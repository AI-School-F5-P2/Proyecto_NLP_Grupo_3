{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones de la biblioteca estándar\n",
    "import re\n",
    "\n",
    "# Importaciones de bibliotecas de terceros relacionadas\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv('../youtoxic_english_1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Consolidar las etiquetas en una sola columna binaria.\n",
    "\n",
    "Para el propósito de crear un modelo de aprendizaje automático que reconozca los mensajes de odio, podemos consolidar las múltiples etiquetas de toxicidad en una sola etiqueta binaria. Por ejemplo, si cualquier columna de etiqueta tiene True, podríamos considerar ese comentario como un mensaje de odio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                Text  IsHate\n",
       " 0  If only people would just take a step back and...   False\n",
       " 1  Law enforcement is not trained to shoot to app...    True\n",
       " 2  \\nDont you reckon them 'black lives matter' ba...    True\n",
       " 3  There are a very large number of people who do...   False\n",
       " 4  The Arab dude is absolutely right, he should h...   False,\n",
       " IsHate\n",
       " False    538\n",
       " True     462\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consolidar las etiquetas en una sola columna binaria 'IsHate'\n",
    "# Consideramos un comentario como mensaje de odio si alguna de las etiquetas relevantes es verdadera\n",
    "columns_to_consider = ['IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', \n",
    "                       'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', \n",
    "                       'IsHomophobic', 'IsReligiousHate', 'IsRadicalism']\n",
    "\n",
    "# Cualquier comentario que tenga al menos una etiqueta positiva se considerará de odio\n",
    "df['IsHate'] = df[columns_to_consider].any(axis=1)\n",
    "\n",
    "# Ahora seleccionamos solo las columnas necesarias, es decir, 'Text' y 'IsHate'\n",
    "data_simplified = df[['Text', 'IsHate']]\n",
    "\n",
    "# Verificamos la distribución de las clases\n",
    "distribution = data_simplified['IsHate'].value_counts()\n",
    "\n",
    "data_simplified.head(), distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El conjunto de datos se ha simplificado para incluir solo el texto del comentario y una etiqueta binaria IsHate.\n",
    "\n",
    "- La distribución de las clases es bastante equilibrada, con 538 comentarios etiquetados como no odio (False) y 462 etiquetados como mensajes de odio (True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento del texto de los comentarios.\n",
    "\n",
    "Este proceso generalmente incluye:\n",
    "\n",
    "- Convertir todo el texto a minúsculas para mantener la consistencia.\n",
    "\n",
    "- Eliminar caracteres especiales y números, que suelen ser irrelevantes para el análisis de sentimiento.\n",
    "\n",
    "- Eliminar las llamadas \"stop words\" (palabras comunes que no aportan significado al contexto).\n",
    "\n",
    "- Tokenizar el texto (dividir el texto en palabras o frases individuales).\n",
    "\n",
    "- Lematizar o realizar stemming (reducir las palabras a su raíz básica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  IsHate\n",
      "0  people would take step back make case wasnt an...   False\n",
      "1  law enforcement trained shoot apprehend traine...    True\n",
      "2  dont reckon black life matter banner held whit...    True\n",
      "3  large number people like police officer called...   False\n",
      "4  arab dude absolutely right shot extra time sho...   False\n"
     ]
    }
   ],
   "source": [
    "# Cargar las stopwords una sola vez\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Función para el preprocesamiento del texto\n",
    "def preprocess_text(text, stop_words):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar caracteres no alfabéticos\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenización\n",
    "    words = word_tokenize(text)\n",
    "    # Eliminar stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Unir las palabras en una cadena de texto de nuevo\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Aplicar el preprocesamiento a cada comentario de forma segura\n",
    "data_simplified.loc[:, 'Text'] = data_simplified['Text'].apply(lambda x: preprocess_text(x, stop_words))\n",
    "\n",
    "# Muestra las primeras filas para verificar\n",
    "print(data_simplified.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La tabla que se muestra al final es el resultado de aplicar tu función de preprocesamiento preprocess_text al DataFrame data_simplified. Muestra las primeras filas con el texto ya preprocesado y la columna IsHate que indica si el comentario es considerado de odio o no.\n",
    "\n",
    "- Esto significa que tu función de preprocesamiento está trabajando como se esperaba: está limpiando y tokenizando el texto, eliminando las stopwords y aplicando la lematización. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vectorizacion y division del conjunto de datos\n",
    "\n",
    "Vamos a:\n",
    "\n",
    "- Vectorizar el texto utilizando TF-IDF.\n",
    "- Dividir el conjunto de datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((800, 4114), (200, 4114)), ((800,), (200,)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorización del texto con TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data_simplified['Text'])\n",
    "\n",
    "# Convertir la columna 'IsHate' a numérica\n",
    "y = data_simplified['IsHate'].astype(int)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos de datos resultantes\n",
    "(X_train.shape, X_test.shape), (y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La vectorización con TF-IDF se ha completado y hemos dividido el conjunto de datos en conjuntos de entrenamiento y prueba. El conjunto de entrenamiento tiene 800 ejemplos, y el conjunto de prueba tiene 200 ejemplos. Cada ejemplo está representado por 4646 características únicas obtenidas del TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entrenamiento de modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  Train Accuracy  Test Accuracy  Overfitting\n",
      "              SVM            1.00          0.680        0.320\n",
      "    Random Forest            1.00          0.680        0.320\n",
      "Gradient Boosting            0.86          0.655        0.205\n",
      "         LightGBM            0.88          0.715        0.165\n",
      "          XGBoost            0.95          0.740        0.210\n"
     ]
    }
   ],
   "source": [
    "# Inicializar los modelos con configuraciones predeterminadas\n",
    "models = {\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# DataFrame para almacenar los resultados de los modelos\n",
    "model_results = pd.DataFrame(columns=['Model', 'Train Accuracy', 'Test Accuracy', 'Overfitting', 'Train Report', 'Test Report', 'Confusion Matrix'])\n",
    "\n",
    "# Función para entrenar y evaluar modelos\n",
    "def train_evaluate(models, X_train, y_train, X_test, y_test):\n",
    "    for name, model in models.items():\n",
    "        # Entrenar el modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predecir en el conjunto de entrenamiento y prueba\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        # Calcular la precisión\n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        # Calcular el sobreajuste\n",
    "        overfitting = accuracy_train - accuracy_test\n",
    "        # Almacenar resultados en el DataFrame\n",
    "        model_results.loc[len(model_results)] = {\n",
    "            'Model': name,\n",
    "            'Train Accuracy': accuracy_train,\n",
    "            'Test Accuracy': accuracy_test,\n",
    "            'Overfitting': overfitting,\n",
    "            'Train Report': classification_report(y_train, y_pred_train),\n",
    "            'Test Report': classification_report(y_test, y_pred_test),\n",
    "            'Confusion Matrix': confusion_matrix(y_test, y_pred_test)\n",
    "        }\n",
    "\n",
    "# Llamar a la función con los modelos y datos\n",
    "train_evaluate(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Configurar Pandas para mostrar todas las filas y columnas en el DataFrame (ajustar si es necesario)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(model_results[['Model', 'Train Accuracy', 'Test Accuracy', 'Overfitting']].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la Validación Cruzada:\n",
      "\n",
      "SVM: 0.66 (+/- 0.03)\n",
      "Random Forest: 0.69 (+/- 0.03)\n",
      "Gradient Boosting: 0.70 (+/- 0.05)\n",
      "LightGBM: 0.67 (+/- 0.02)\n",
      "XGBoost: 0.68 (+/- 0.02)\n",
      "\n",
      "Matrices de Confusión:\n",
      "\n",
      "SVM:\n",
      "[[86  7]\n",
      " [57 50]]\n",
      "\n",
      "Random Forest:\n",
      "[[79 14]\n",
      " [50 57]]\n",
      "\n",
      "Gradient Boosting:\n",
      "[[82 11]\n",
      " [58 49]]\n",
      "\n",
      "LightGBM:\n",
      "[[77 16]\n",
      " [41 66]]\n",
      "\n",
      "XGBoost:\n",
      "[[78 15]\n",
      " [37 70]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Configuración para la validación cruzada\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# DataFrames para almacenar los resultados\n",
    "confusion_matrices = {}\n",
    "cross_val_results = {}\n",
    "\n",
    "# Realizar validación cruzada y calcular la matriz de confusión\n",
    "for name, model in models.items():\n",
    "    # Validación cruzada\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    cross_val_results[name] = cv_scores\n",
    "    \n",
    "    # Entrenar y predecir para calcular la matriz de confusión\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[name] = conf_matrix\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Resultados de la Validación Cruzada:\\n\")\n",
    "for name, scores in cross_val_results.items():\n",
    "    print(f\"{name}: {scores.mean():.2f} (+/- {scores.std():.2f})\")\n",
    "\n",
    "print(\"\\nMatrices de Confusión:\\n\")\n",
    "for name, matrix in confusion_matrices.items():\n",
    "    print(f\"{name}:\\n{matrix}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la validación cruzada te proporcionan dos piezas de información clave sobre cada modelo de clasificación:\n",
    "\n",
    "- Precisión Media: Es el valor promedio de la precisión (accuracy) que el modelo logra en los diferentes conjuntos de datos creados durante la validación cruzada. La precisión es la proporción de predicciones correctas (tanto positivas como negativas) entre todas las predicciones realizadas. Un valor más alto es mejor.\n",
    "\n",
    "- Desviación Estándar de la Precisión: Es una medida de cuánto varía la precisión del modelo en los diferentes conjuntos de datos de la validación cruzada. Una desviación estándar baja significa que el modelo tiene un rendimiento más consistente y es menos sensible a las diferencias en los conjuntos de datos específicos utilizados para entrenamiento y prueba.\n",
    "\n",
    "Para cada modelo, tienes un valor de precisión media seguido de un signo ± y un valor de desviación estándar. \n",
    "\n",
    "Aquí está el desglose:\n",
    "\n",
    "- SVM: Tiene una precisión media del 66% con una variabilidad de 0.03 puntos porcentuales. Esto significa que, en promedio, el modelo clasifica correctamente el 66% de las muestras, y esta precisión varía en un rango de 3% hacia arriba o hacia abajo en diferentes pruebas.\n",
    "\n",
    "- Random Forest: Tiene una precisión media del 69% con una variabilidad del 3%. Esto indica que es ligeramente más preciso que el SVM en promedio, con la misma cantidad de variabilidad en su rendimiento.\n",
    "\n",
    "- Gradient Boosting: Tiene la precisión media más alta con 70%, pero con una variabilidad del 5%, lo que sugiere que su rendimiento podría cambiar más entre diferentes pruebas en comparación con los modelos SVM y Random Forest.\n",
    "\n",
    "- LightGBM: Tiene una precisión media del 67% con una variabilidad del 2%, lo que indica un rendimiento ligeramente mejor que el SVM pero menor que el Random Forest y Gradient Boosting, aunque con un rendimiento muy consistente.\n",
    "\n",
    "- XGBoost: Muestra una precisión media del 68% con una variabilidad del 2%, lo que significa que es más preciso que el SVM y el LightGBM pero menos que el Random Forest y el Gradient Boosting, con un rendimiento bastante estable a través de diferentes pruebas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
